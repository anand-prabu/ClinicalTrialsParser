<?xml version="1.0" encoding="UTF-8"?>
<clinical_study rank="58644">
  <!-- This xml conforms to an XML Schema at:
    http://clinicaltrials.gov/ct2/html/images/info/public.xsd
 and an XML DTD at:
    http://clinicaltrials.gov/ct2/html/images/info/public.dtd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on June 04, 2014</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>http://clinicaltrials.gov/show/NCT01821534</url>
  </required_header>
  <id_info>
    <org_study_id>191622-128</org_study_id>
    <nct_id>NCT01821534</nct_id>
  </id_info>
  <brief_title>Reliability of a Masseter Muscle Prominence Scale and Lower Facial Shape Classification</brief_title>
  <sponsors>
    <lead_sponsor>
      <agency>Allergan</agency>
      <agency_class>Industry</agency_class>
    </lead_sponsor>
  </sponsors>
  <source>Allergan</source>
  <oversight_info>
    <authority>United States: Institutional Review Board</authority>
    <has_dmc>No</has_dmc>
  </oversight_info>
  <brief_summary>
    <textblock>
      This study will evaluate the inter-rater and intra-rater reliability of a Masseter Muscle
      Prominence Scale for evaluating a patient's muscle prominence and a Lower Shape
      Classification for evaluating a patient's lower facial shape.
    </textblock>
  </brief_summary>
  <overall_status>Completed</overall_status>
  <start_date>March 2013</start_date>
  <completion_date type="Actual">May 2013</completion_date>
  <primary_completion_date type="Actual">May 2013</primary_completion_date>
  <phase>N/A</phase>
  <study_type>Observational</study_type>
  <study_design>Observational Model: Cohort, Time Perspective: Prospective</study_design>
  <primary_outcome>
    <measure>Inter-rater Reliability Using a Masseter Muscle Prominence Scale (MMPS)</measure>
    <time_frame>Day 1</time_frame>
    <safety_issue>No</safety_issue>
    <description>The MMPS is an ordinal tool to assess the masseter muscle prominence (jaw muscle) for each side of the face from 1=minimal to 5=very marked. Inter-rater (among raters) reliability was calculated separately for the left and right side of the face using Kendall's coefficient of concordance (Kendall's W). Kendall W statistics overall for the left and right sides of the face were derived using the average of assessment 1 and assessment 2 rounded to the nearest whole integer for each subject and each clinician. A total of 8 physicians rated each subject. The degree of agreement of the point estimates of Kendall's W was interpreted according to the reference range scale that was pre-defined as: ≤0: poor, &gt;0 to ≤0.2: slight, &gt;0.2 to ≤0.4: fair, &gt;0.4 to ≤0.6: moderate, &gt;0.6 to ≤0.8: substantial, and &gt;0.8 to ≤1.0: almost perfect. The 95% confidence interval for Kendall's W is provided.</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Intra-rater Reliability Using a MMPS</measure>
    <time_frame>Day 1</time_frame>
    <safety_issue>No</safety_issue>
    <description>The MMPS is an ordinal tool to assess the masseter muscle prominence (jaw muscle) for each side of the face from 1 = minimal to 5 = very marked. Intra-rater (within raters) reliability was calculated separately for the left and right side of the face using weighted Kappa statistics. Weighted Kappa statistics were calculated for each of the 8 physician raters. The overall intra-rater agreement for Kappa statistics for all raters combined was estimated by pooling Kappa statistics for each rater using a chi-square statistic. The degree of agreement of the point estimates of Kappa statistics was interpreted according to the reference range scale that was pre-defined as: ≤0: poor, &gt;0 to ≤0.2: slight, &gt;0.2 to ≤0.4: fair, &gt;0.4 to ≤0.6: moderate, &gt;0.6 to ≤0.8: substantial, and &gt;0.8 to ≤1.0: almost perfect. The 95% confidence interval for Kappa statistics is provided.</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Inter-rater Reliability Using a Lower Facial Shape Classification (LFSC)</measure>
    <time_frame>Day 1</time_frame>
    <safety_issue>No</safety_issue>
    <description>The LFSC is a qualitative tool to assess facial shape into one of 5 categories (A, B, C, D, and E). Inter-rater (among raters) reliability was calculated using Kappa statistics. Kappa statistics were calculated for each of the 5 facial categories. A total of 8 physicians rated each subject. The overall inter-rater agreement for Kappa statistics for all categories combined was estimated by pooling Kappa statistics for each category using a chi-square statistic. The degree of agreement of the point estimates of Kappa statistics was interpreted according to the reference range scale that was pre-defined as: ≤0: poor, &gt;0 to ≤0.2: slight, &gt;0.2 to ≤0.4: fair, &gt;0.4 to ≤0.6: moderate, &gt;0.6 to ≤0.8: substantial, and &gt;0.8 to ≤1.0: almost perfect. The 95% confidence interval for Kappa statistics is provided.</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Intra-rater Reliability Using a LFSC</measure>
    <time_frame>Day 1</time_frame>
    <safety_issue>No</safety_issue>
    <description>The LFSC is a qualitative tool to assess facial shape into one of 5 categories (A, B, C, D, and E). Intra-rater (within raters) reliability was calculated using Kappa statistics. Kappa statistics were calculated for each of the 8 physician raters. The overall intra-rater agreement for Kappa statistics for all raters combined was estimated by pooling Kappa statistics for each rater using a chi-square statistic. The degree of agreement of the point estimates of Kappa statistics was interpreted according to the reference range scale that was pre-defined as: ≤0: poor, &gt;0 to ≤0.2: slight, &gt;0.2 to ≤0.4: fair, &gt;0.4 to ≤0.6: moderate, &gt;0.6 to ≤0.8: substantial, and &gt;0.8 to ≤1.0: almost perfect. The 95% confidence interval for Kappa statistics is provided.</description>
  </primary_outcome>
  <number_of_groups>1</number_of_groups>
  <enrollment type="Actual">201</enrollment>
  <condition>Healthy Volunteers</condition>
  <arm_group>
    <arm_group_label>All Participants</arm_group_label>
    <description>Healthy volunteers. No treatment (intervention) was administered.</description>
  </arm_group>
  <intervention>
    <intervention_type>Other</intervention_type>
    <intervention_name>No Intervention</intervention_name>
    <description>No treatment (intervention) was administered.</description>
    <arm_group_label>All Participants</arm_group_label>
  </intervention>
  <eligibility>
    <study_pop>
      <textblock>
        Healthy Volunteers
      </textblock>
    </study_pop>
    <sampling_method>Probability Sample</sampling_method>
    <criteria>
      <textblock>
        Inclusion Criteria:

        -sufficient visual acuity without the use of glasses or with contact lenses to self-assess
        lower facial shape in a mirror

        Exclusion Criteria:

          -  infection of the mouth or gums, or facial skin infection requiring antibiotics

          -  planned dental or facial procedure

          -  unwillingness to be photographed and have the photos used for research, training, or
             educational purposes
      </textblock>
    </criteria>
    <gender>Both</gender>
    <minimum_age>18 Years</minimum_age>
    <maximum_age>N/A</maximum_age>
    <healthy_volunteers>Accepts Healthy Volunteers</healthy_volunteers>
  </eligibility>
  <overall_official>
    <last_name>Medical Director</last_name>
    <role>Study Director</role>
    <affiliation>Allergan</affiliation>
  </overall_official>
  <location>
    <facility>
      <address>
        <city>Newport Beach</city>
        <state>California</state>
        <country>United States</country>
      </address>
    </facility>
  </location>
  <location_countries>
    <country>United States</country>
  </location_countries>
  <verification_date>March 2014</verification_date>
  <lastchanged_date>March 28, 2014</lastchanged_date>
  <firstreceived_date>March 25, 2013</firstreceived_date>
  <firstreceived_results_date>March 28, 2014</firstreceived_results_date>
  <responsible_party>
    <responsible_party_type>Sponsor</responsible_party_type>
  </responsible_party>
  <is_fda_regulated>No</is_fda_regulated>
  <has_expanded_access>No</has_expanded_access>

  <clinical_results>

    <participant_flow>
      <group_list>
        <group group_id="P1">
          <title>All Participants</title>
          <description>Healthy volunteers. No treatment (intervention) was administered.</description>
        </group>
      </group_list>
      <period_list>
        <period>
          <title>Overall Study</title>
          <milestone_list>
            <milestone>
              <title>STARTED</title>
              <participants_list>
                <participants group_id="P1" count="201"/>
              </participants_list>
            </milestone>
            <milestone>
              <title>COMPLETED</title>
              <participants_list>
                <participants group_id="P1" count="201"/>
              </participants_list>
            </milestone>
            <milestone>
              <title>NOT COMPLETED</title>
              <participants_list>
                <participants group_id="P1" count="0"/>
              </participants_list>
            </milestone>
          </milestone_list>
        </period>
      </period_list>
    </participant_flow>

    <baseline>
      <group_list>
        <group group_id="B1">
          <title>All Participants</title>
          <description>Healthy volunteers. No treatment (intervention) was administered.</description>
        </group>
      </group_list>
      <measure_list>
        <measure>
          <title>Number of Participants</title>
          <units>participants</units>
          <param>Number</param>
          <category_list>
            <category>
              <measurement_list>
                <measurement group_id="B1" value="201"/>
              </measurement_list>
            </category>
          </category_list>
        </measure>
        <measure>
          <title>Age</title>
          <units>Years</units>
          <param>Mean</param>
          <dispersion>Standard Deviation</dispersion>
          <category_list>
            <category>
              <measurement_list>
                <measurement group_id="B1" value="35.5" spread="11.43"/>
              </measurement_list>
            </category>
          </category_list>
        </measure>
        <measure>
          <title>Gender</title>
          <units>Participants</units>
          <param>Number</param>
          <category_list>
            <category>
              <sub_title>Female</sub_title>
              <measurement_list>
                <measurement group_id="B1" value="128"/>
              </measurement_list>
            </category>
            <category>
              <sub_title>Male</sub_title>
              <measurement_list>
                <measurement group_id="B1" value="73"/>
              </measurement_list>
            </category>
          </category_list>
        </measure>
      </measure_list>
    </baseline>

    <outcome_list>
      <outcome>
        <type>Primary</type>
        <title>Inter-rater Reliability Using a Masseter Muscle Prominence Scale (MMPS)</title>
        <description>The MMPS is an ordinal tool to assess the masseter muscle prominence (jaw muscle) for each side of the face from 1=minimal to 5=very marked. Inter-rater (among raters) reliability was calculated separately for the left and right side of the face using Kendall’s coefficient of concordance (Kendall's W). Kendall W statistics overall for the left and right sides of the face were derived using the average of assessment 1 and assessment 2 rounded to the nearest whole integer for each subject and each clinician. A total of 8 physicians rated each subject. The degree of agreement of the point estimates of Kendall's W was interpreted according to the reference range scale that was pre-defined as: ≤0: poor, &gt;0 to ≤0.2: slight, &gt;0.2 to ≤0.4: fair, &gt;0.4 to ≤0.6: moderate, &gt;0.6 to ≤0.8: substantial, and &gt;0.8 to ≤1.0: almost perfect. The 95% confidence interval for Kendall's W is provided.</description>
        <time_frame>Day 1</time_frame>
        <safety_issue>No</safety_issue>
        <population>Reliability population: all subjects with at least assessment 1 performed by at least 1 in-person rater on day 1</population>
        <group_list>
          <group group_id="O1">
            <title>All Participants</title>
            <description>Healthy volunteers. No treatment (intervention) was administered.</description>
          </group>
        </group_list>
        <measure_list>
          <measure>
            <title>Number of Participants</title>
            <units>participants</units>
            <param>Number</param>
            <category_list>
              <category>
                <measurement_list>
                  <measurement group_id="O1" value="201"/>
                </measurement_list>
              </category>
            </category_list>
          </measure>
          <measure>
            <title>Inter-rater Reliability Using a Masseter Muscle Prominence Scale (MMPS)</title>
            <description>The MMPS is an ordinal tool to assess the masseter muscle prominence (jaw muscle) for each side of the face from 1=minimal to 5=very marked. Inter-rater (among raters) reliability was calculated separately for the left and right side of the face using Kendall’s coefficient of concordance (Kendall's W). Kendall W statistics overall for the left and right sides of the face were derived using the average of assessment 1 and assessment 2 rounded to the nearest whole integer for each subject and each clinician. A total of 8 physicians rated each subject. The degree of agreement of the point estimates of Kendall's W was interpreted according to the reference range scale that was pre-defined as: ≤0: poor, &gt;0 to ≤0.2: slight, &gt;0.2 to ≤0.4: fair, &gt;0.4 to ≤0.6: moderate, &gt;0.6 to ≤0.8: substantial, and &gt;0.8 to ≤1.0: almost perfect. The 95% confidence interval for Kendall's W is provided.</description>
            <units>Kendall's W</units>
            <param>Number</param>
            <dispersion>95% Confidence Interval</dispersion>
            <category_list>
              <category>
                <sub_title>Left Side</sub_title>
                <measurement_list>
                  <measurement group_id="O1" value="0.728" lower_limit="0.677" upper_limit="0.786"/>
                </measurement_list>
              </category>
              <category>
                <sub_title>Right Side</sub_title>
                <measurement_list>
                  <measurement group_id="O1" value="0.711" lower_limit="0.661" upper_limit="0.767"/>
                </measurement_list>
              </category>
            </category_list>
          </measure>
        </measure_list>
      </outcome>
      <outcome>
        <type>Primary</type>
        <title>Intra-rater Reliability Using a MMPS</title>
        <description>The MMPS is an ordinal tool to assess the masseter muscle prominence (jaw muscle) for each side of the face from 1 = minimal to 5 = very marked. Intra-rater (within raters) reliability was calculated separately for the left and right side of the face using weighted Kappa statistics. Weighted Kappa statistics were calculated for each of the 8 physician raters. The overall intra-rater agreement for Kappa statistics for all raters combined was estimated by pooling Kappa statistics for each rater using a chi-square statistic. The degree of agreement of the point estimates of Kappa statistics was interpreted according to the reference range scale that was pre-defined as: ≤0: poor, &gt;0 to ≤0.2: slight, &gt;0.2 to ≤0.4: fair, &gt;0.4 to ≤0.6: moderate, &gt;0.6 to ≤0.8: substantial, and &gt;0.8 to ≤1.0: almost perfect. The 95% confidence interval for Kappa statistics is provided.</description>
        <time_frame>Day 1</time_frame>
        <safety_issue>No</safety_issue>
        <population>Reliability population: all subjects with at least assessment 1 performed by at least 1 in-person rater on day 1</population>
        <group_list>
          <group group_id="O1">
            <title>All Participants</title>
            <description>Healthy volunteers. No treatment (intervention) was administered.</description>
          </group>
        </group_list>
        <measure_list>
          <measure>
            <title>Number of Participants</title>
            <units>participants</units>
            <param>Number</param>
            <category_list>
              <category>
                <measurement_list>
                  <measurement group_id="O1" value="201"/>
                </measurement_list>
              </category>
            </category_list>
          </measure>
          <measure>
            <title>Intra-rater Reliability Using a MMPS</title>
            <description>The MMPS is an ordinal tool to assess the masseter muscle prominence (jaw muscle) for each side of the face from 1 = minimal to 5 = very marked. Intra-rater (within raters) reliability was calculated separately for the left and right side of the face using weighted Kappa statistics. Weighted Kappa statistics were calculated for each of the 8 physician raters. The overall intra-rater agreement for Kappa statistics for all raters combined was estimated by pooling Kappa statistics for each rater using a chi-square statistic. The degree of agreement of the point estimates of Kappa statistics was interpreted according to the reference range scale that was pre-defined as: ≤0: poor, &gt;0 to ≤0.2: slight, &gt;0.2 to ≤0.4: fair, &gt;0.4 to ≤0.6: moderate, &gt;0.6 to ≤0.8: substantial, and &gt;0.8 to ≤1.0: almost perfect. The 95% confidence interval for Kappa statistics is provided.</description>
            <units>Kappa statistics</units>
            <param>Number</param>
            <dispersion>95% Confidence Interval</dispersion>
            <category_list>
              <category>
                <sub_title>Left Side</sub_title>
                <measurement_list>
                  <measurement group_id="O1" value="0.634" lower_limit="0.607" upper_limit="0.660"/>
                </measurement_list>
              </category>
              <category>
                <sub_title>Right Side</sub_title>
                <measurement_list>
                  <measurement group_id="O1" value="0.638" lower_limit="0.611" upper_limit="0.665"/>
                </measurement_list>
              </category>
            </category_list>
          </measure>
        </measure_list>
      </outcome>
      <outcome>
        <type>Primary</type>
        <title>Inter-rater Reliability Using a Lower Facial Shape Classification (LFSC)</title>
        <description>The LFSC is a qualitative tool to assess facial shape into one of 5 categories (A, B, C, D, and E). Inter-rater (among raters) reliability was calculated using Kappa statistics. Kappa statistics were calculated for each of the 5 facial categories. A total of 8 physicians rated each subject. The overall inter-rater agreement for Kappa statistics for all categories combined was estimated by pooling Kappa statistics for each category using a chi-square statistic. The degree of agreement of the point estimates of Kappa statistics was interpreted according to the reference range scale that was pre-defined as: ≤0: poor, &gt;0 to ≤0.2: slight, &gt;0.2 to ≤0.4: fair, &gt;0.4 to ≤0.6: moderate, &gt;0.6 to ≤0.8: substantial, and &gt;0.8 to ≤1.0: almost perfect. The 95% confidence interval for Kappa statistics is provided.</description>
        <time_frame>Day 1</time_frame>
        <safety_issue>No</safety_issue>
        <population>Reliability population: all subjects with at least assessment 1 performed by at least 1 in-person rater on day 1</population>
        <group_list>
          <group group_id="O1">
            <title>All Participants</title>
            <description>Healthy volunteers. No treatment (intervention) was administered.</description>
          </group>
        </group_list>
        <measure_list>
          <measure>
            <title>Number of Participants</title>
            <units>participants</units>
            <param>Number</param>
            <category_list>
              <category>
                <measurement_list>
                  <measurement group_id="O1" value="201"/>
                </measurement_list>
              </category>
            </category_list>
          </measure>
          <measure>
            <title>Inter-rater Reliability Using a Lower Facial Shape Classification (LFSC)</title>
            <description>The LFSC is a qualitative tool to assess facial shape into one of 5 categories (A, B, C, D, and E). Inter-rater (among raters) reliability was calculated using Kappa statistics. Kappa statistics were calculated for each of the 5 facial categories. A total of 8 physicians rated each subject. The overall inter-rater agreement for Kappa statistics for all categories combined was estimated by pooling Kappa statistics for each category using a chi-square statistic. The degree of agreement of the point estimates of Kappa statistics was interpreted according to the reference range scale that was pre-defined as: ≤0: poor, &gt;0 to ≤0.2: slight, &gt;0.2 to ≤0.4: fair, &gt;0.4 to ≤0.6: moderate, &gt;0.6 to ≤0.8: substantial, and &gt;0.8 to ≤1.0: almost perfect. The 95% confidence interval for Kappa statistics is provided.</description>
            <units>Kappa Statistics</units>
            <param>Number</param>
            <dispersion>95% Confidence Interval</dispersion>
            <category_list>
              <category>
                <sub_title>Assessment 1</sub_title>
                <measurement_list>
                  <measurement group_id="O1" value="0.358" lower_limit="0.343" upper_limit="0.372"/>
                </measurement_list>
              </category>
              <category>
                <sub_title>Assessment 2</sub_title>
                <measurement_list>
                  <measurement group_id="O1" value="0.352" lower_limit="0.337" upper_limit="0.367"/>
                </measurement_list>
              </category>
            </category_list>
          </measure>
        </measure_list>
      </outcome>
      <outcome>
        <type>Primary</type>
        <title>Intra-rater Reliability Using a LFSC</title>
        <description>The LFSC is a qualitative tool to assess facial shape into one of 5 categories (A, B, C, D, and E). Intra-rater (within raters) reliability was calculated using Kappa statistics. Kappa statistics were calculated for each of the 8 physician raters. The overall intra-rater agreement for Kappa statistics for all raters combined was estimated by pooling Kappa statistics for each rater using a chi-square statistic. The degree of agreement of the point estimates of Kappa statistics was interpreted according to the reference range scale that was pre-defined as: ≤0: poor, &gt;0 to ≤0.2: slight, &gt;0.2 to ≤0.4: fair, &gt;0.4 to ≤0.6: moderate, &gt;0.6 to ≤0.8: substantial, and &gt;0.8 to ≤1.0: almost perfect. The 95% confidence interval for Kappa statistics is provided.</description>
        <time_frame>Day 1</time_frame>
        <safety_issue>No</safety_issue>
        <population>Reliability population: all subjects with at least assessment 1 performed by at least 1 in-person rater on day 1</population>
        <group_list>
          <group group_id="O1">
            <title>All Participants</title>
            <description>Healthy volunteers. No treatment (intervention) was administered.</description>
          </group>
        </group_list>
        <measure_list>
          <measure>
            <title>Number of Participants</title>
            <units>participants</units>
            <param>Number</param>
            <category_list>
              <category>
                <measurement_list>
                  <measurement group_id="O1" value="201"/>
                </measurement_list>
              </category>
            </category_list>
          </measure>
          <measure>
            <title>Intra-rater Reliability Using a LFSC</title>
            <description>The LFSC is a qualitative tool to assess facial shape into one of 5 categories (A, B, C, D, and E). Intra-rater (within raters) reliability was calculated using Kappa statistics. Kappa statistics were calculated for each of the 8 physician raters. The overall intra-rater agreement for Kappa statistics for all raters combined was estimated by pooling Kappa statistics for each rater using a chi-square statistic. The degree of agreement of the point estimates of Kappa statistics was interpreted according to the reference range scale that was pre-defined as: ≤0: poor, &gt;0 to ≤0.2: slight, &gt;0.2 to ≤0.4: fair, &gt;0.4 to ≤0.6: moderate, &gt;0.6 to ≤0.8: substantial, and &gt;0.8 to ≤1.0: almost perfect. The 95% confidence interval for Kappa statistics is provided.</description>
            <units>Kappa statistics</units>
            <param>Number</param>
            <dispersion>95% Confidence Interval</dispersion>
            <category_list>
              <category>
                <measurement_list>
                  <measurement group_id="O1" value="0.658" lower_limit="0.629" upper_limit="0.686"/>
                </measurement_list>
              </category>
            </category_list>
          </measure>
        </measure_list>
      </outcome>
    </outcome_list>

    <certain_agreements>
      <pi_employee>Principal Investigators are NOT employed by the organization sponsoring the study.</pi_employee>
      <restrictive_agreement>A disclosure restriction on the PI is that the sponsor can review results communications prior to public release and can embargo communications regarding trial results for a period that is less than or equal to 90 days from the time submitted to the sponsor for review. The sponsor cannot require changes to the communication and cannot extend the embargo.</restrictive_agreement>
    </certain_agreements>
    <point_of_contact>
      <name_or_title>Therapeutic  Area Head,</name_or_title>
      <organization>Allergan, Inc</organization>
      <phone>714-246-4500</phone>
      <email>clinicaltrials@allergan.com</email>
    </point_of_contact>
  </clinical_results>
</clinical_study>
